{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "context has already been set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m logging\u001b[39m.\u001b[39mbasicConfig(level\u001b[39m=\u001b[39mlogging\u001b[39m.\u001b[39mWARNING, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%(asctime)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(message)s\u001b[39;00m\u001b[39m'\u001b[39m, datefmt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm/\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY \u001b[39m\u001b[39m%\u001b[39m\u001b[39mI:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS \u001b[39m\u001b[39m%\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmp\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m mp\u001b[39m.\u001b[39;49mset_start_method(\u001b[39m'\u001b[39;49m\u001b[39mfork\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.10/multiprocessing/context.py:247\u001b[0m, in \u001b[0;36mDefaultContext.set_start_method\u001b[0;34m(self, method, force)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_start_method\u001b[39m(\u001b[39mself\u001b[39m, method, force\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actual_context \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m force:\n\u001b[0;32m--> 247\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcontext has already been set\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    248\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m force:\n\u001b[1;32m    249\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actual_context \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: context has already been set"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import vectorbtpro as vbt\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "import logging\n",
    "from backtesting import Strategy, Backtest\n",
    "from backtesting.lib import resample_apply\n",
    "logging.basicConfig(level=logging.WARNING, format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = \"2018-01-01\"\n",
    "# Enter your parameters here\n",
    "metric = 'total_return'\n",
    "\n",
    "start_date = datetime(2020, 1, 1, tzinfo=pytz.utc)  # time period for analysis, must be timezone-aware\n",
    "end_date = datetime.now(pytz.utc)\n",
    "# end_date = datetime(2020, 1, 1, tzinfo=pytz.utc)\n",
    "\n",
    "# The following is the number of days to look back for the analysis\n",
    "time_buffer = timedelta(days=100)  # buffer before to pre-calculate SMA/EMA, best to set to max window\n",
    "freq = '1h'\n",
    "\n",
    "vbt.settings.portfolio['init_cash'] = 100_000.  # 100,000$\n",
    "# vbt.settings.portfolio['fees'] = 0.0025  # 0.25%\n",
    "# vbt.settings.portfolio['slippage'] = 0.0025  # 0.25%\n",
    "\n",
    "# get binance data doing it this way allows for you to update your data rather than re-downloading it\n",
    "# binance_data = vbt.BinanceData.fetch(symbols,timeframe=freq, start=start_date,end=\"now UTC\")\n",
    "# binance_data.save(\"binance_data.pkl\")\n",
    "\n",
    "# If you already have the data downloaded, you can load it\n",
    "# binance_data = vbt.BinanceData.load(\"binance_data.pkl\")\n",
    "# binance_data = binance_data.update() if you want to update it.\n",
    "futures_path = '/Users/ericervin/Documents/Coding/data-repository/data/BTCUSDT_1m_futures.pkl'\n",
    "# You can grab the necessary file from this google drive link. https://drive.google.com/drive/folders/1jKy2DMbBow-J5jTvPutw-j17m7Ss8R3i?usp=drive_link"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have the datafile yet you can grab it from this [link](https://drive.google.com/drive/folders/1jKy2DMbBow-J5jTvPutw-j17m7Ss8R3i?usp=drive_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc = vbt.BinanceData.load(futures_path)\n",
    "df = btc.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a signal array the same length as the dataframe\n",
    "signal = np.zeros(len(df))\n",
    "signal = pd.Series(signal, index=df.index)\n",
    "# set the signal to 1 at midnight UTC\n",
    "signal[df.at_time('00:00').index] = 1\n",
    "# Create a -1 right before the signal\n",
    "signal[df.at_time('23:59').index] = -1 # for exiting 1 minute before midnight\n",
    "df['signal'] = signal\n",
    "# Convert to int\n",
    "df['signal'] = df['signal'].astype(int)\n",
    "df['signal'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class SHORTING_Underwater_w_decay_and_deleverage(Strategy):\n",
    "    # All of the following variables can be used during optimization\n",
    "    initial_position_size = 0.3\n",
    "    percent_invested_threshold = 0.50 \n",
    "    atr_length = 14 # 14 days\n",
    "    atr_multiplier = 0.5\n",
    "    add_size = 0.30\n",
    "    delay_period = 1000\n",
    "    delta_time = 5000\n",
    "    upper_bound_profit_target = 0.10\n",
    "    lower_bound_loss_threshold = -0.05\n",
    "    take_profit_loss_reduction = -0.1 # This is the amount that the take profit is reduced by if the position is highly leveraged and we wish to trim\n",
    "    deleverage_pct = 0.30 # This is the amount that the position is reduced by if the position is highly leveraged and we wish to trim\n",
    "    \n",
    "    def SIGNAL(self):\n",
    "        return self.data.signal\n",
    "\n",
    "    def ATR(self, df, length):\n",
    "        return df.ta.atr(length=length)\n",
    "    \n",
    "    def bars_since_first_trade(self, use_for_indexing=False): \n",
    "        \"\"\"\n",
    "        Calculate the number of bars since the first trade was entered.\n",
    "        If use for indexing is true then it will return 1 if there are no trades. \n",
    "        This way you can retrieve the last element of a list by applying a - to the return value.\n",
    "        eg. self.equity[-self.bars_since_first_trade(use_for_indexing=True):] gives you the array of your account's equity since you entered the first trade that is currently open\n",
    "        \"\"\"\n",
    "        if len(self.trades) > 0 and self.trades[0].is_short:\n",
    "            self.first_trade_entry_bar = self.trades[0].entry_bar\n",
    "            bars_since_first_trade = len(self.data.Close) - self.first_trade_entry_bar\n",
    "            return bars_since_first_trade\n",
    "        elif use_for_indexing:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def custom_decay_func(self, x, delay_period, upper_bound_profit_target, lower_bound_loss_threshold, delta_time):\n",
    "        \"\"\"\n",
    "        This function is used to calculate the decayed take profit x represents the number of bars since the first trade was entered\n",
    "        x is the number of bars since the first trade was entered\n",
    "        delay_period is the number of bars to wait before starting to decay\n",
    "        upper_bound_profit_target is the upper bound of the take profit\n",
    "        lower_bound_loss_threshold is the lower bound of the take profit\n",
    "        delta_time is the number of bars over which to transition from the upper bound to the lower bound\n",
    "        \"\"\"\n",
    "        if x <= delay_period:\n",
    "            return upper_bound_profit_target\n",
    "        elif delay_period < x < delay_period + delta_time:\n",
    "            # Calculate the x value for the cos function\n",
    "            transition_x = (x - delay_period) / delta_time * np.pi\n",
    "            # Calculate the decayed take profit\n",
    "            return (-np.cos(transition_x) + 1) / 2 * (lower_bound_loss_threshold - upper_bound_profit_target) + upper_bound_profit_target\n",
    "        else:\n",
    "            return lower_bound_loss_threshold\n",
    "    \n",
    "    def init(self):\n",
    "        super().init()\n",
    "        self.signal = self.I(self.SIGNAL)\n",
    "        self.atr = self.I(self.ATR, self.data.df, self.atr_length)\n",
    "        self.daily_atr = resample_apply('1D', self.ATR, self.data.df, length=14)\n",
    "        count_NaN = len(self.atr) - len(pd.Series(self.atr).dropna()) # This is used for the progress bar\n",
    "        self.length_of_data = len(self.data.Close) - count_NaN # This is used for the progress bar\n",
    "        self.equity_during_trade = [] # Keeps a list for the equity during the trade\n",
    "        \n",
    "    def next(self):\n",
    "        super().next()\n",
    "\n",
    "        price = self.data.Close[-1]\n",
    "        position_value = self.position.size*price\n",
    "        percent_invested = position_value/self.equity # this will come in handy if we decide to change behavior once XX% is invested\n",
    "        atr_threshold_pct = self.atr_multiplier*self.daily_atr[-1]/price # This is the ATR threshold times a multiplier calculated as a percentage of price\n",
    "        bars_since_trade_open = self.bars_since_first_trade(use_for_indexing=True)\n",
    "        highly_leveraged = percent_invested > self.percent_invested_threshold\n",
    "        # Calculate the decayed take profit\n",
    "        decayed_take_profit = self.custom_decay_func(bars_since_trade_open, self.delay_period, self.upper_bound_profit_target, self.lower_bound_loss_threshold, self.delta_time)\n",
    "        \n",
    "        # Keep a running list of the self.equity values while we have a trade open\n",
    "        if self.position.size < 0:\n",
    "            self.equity_during_trade.append(self.equity)\n",
    "        else:\n",
    "            self.equity_during_trade = []\n",
    "        \n",
    "        low_point_in_trade = min(self.equity_during_trade, default=0)\n",
    "        bounce_from_low_pct = (lambda x: (self.equity - x) / x if x != 0 else 0)(low_point_in_trade) # The lambda function is used to avoid a divide by zero error\n",
    "\n",
    "        if self.position.pl_pct > decayed_take_profit:\n",
    "            self.position.close()\n",
    "\n",
    "        # Deleverage if we are over a certain percent invested and the market is recovering from the low point\n",
    "        elif highly_leveraged and bounce_from_low_pct > 1.5*atr_threshold_pct: # TODO: maybe make this a parameter we can tune\n",
    "            # TODO: this is crude but it works for now\n",
    "            # For now, just trim 20% of the position if we are within 5% of the take profit\n",
    "            if self.position.pl_pct > decayed_take_profit + self.take_profit_loss_reduction:\n",
    "                self.position.close(portion = self.deleverage_pct)\n",
    "                \n",
    "            \n",
    "        elif self.position.size < 0 and self.position.pl_pct < -atr_threshold_pct: \n",
    "            # Check to see if we are also down on our last trade\n",
    "            if self.trades[-1].pl_pct < -atr_threshold_pct:\n",
    "                self.sell(size = self.add_size)\n",
    "                \n",
    "        elif not self.position and self.signal == 1:\n",
    "            self.sell(size = self.initial_position_size) \n",
    "\n",
    "start = '2022-05-01' # Note the strategy requires a warmup period for the ATR to calculate first trades begin after 14 days\n",
    "end = '2022-12-03' # It will always close any open trades at the end of the backtest\n",
    "bt = Backtest(df.loc[start:end], SHORTING_Underwater_w_decay_and_deleverage, cash=100_000_000, exclusive_orders=False, trade_on_close=True, margin=0.5)\n",
    "stats = bt.run()\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
